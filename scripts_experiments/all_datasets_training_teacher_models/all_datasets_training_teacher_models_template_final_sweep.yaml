program: /home/timoh/L46_datamaps/run_experiment.py # Path to the program to run
project: all_datasets_training_teacher_models # Project name

name: all_datasets_training_teacher_models

# it's not possible to add booleans, thus they must be defined directly in args. 
# https://github.com/wandb/wandb/issues/1700
command:
- ${env}
- ${interpreter}
- ${program}
- --notes
- "Training large teacher models (with training dynamic calculation) to identify ideal hyperparameters"
- ${args}
- --model_size
- large
- --model_name
- DUMMY_STR # CHANGE HERE
- --epochs
- 10 
- --optimizer
- Adam 
- --learning_rate
- 0.001 # CHANGE HERE
- --force_full_epoch_training
- --track_training_dynamics
- --pretrained # CHANGE HERE (remove if needed)
- --freeze_pretrained # CHANGE HERE (remove if needed)

# potentially define individual datasets if we need to change hparams across datasets
method: grid
parameters:
  dataset:
    distribution: categorical
    values:
      - cifar10
      - cifar100
      - mnist

  val_split_seed:
    distribution: categorical
    values:
      - 42
      - 43
      - 44
